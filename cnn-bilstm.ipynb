{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Utility packages ","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings( 'ignore' )\nimport gc\nimport os\nimport time\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.metrics import f1_score, confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\n\nimport tensorflow as tf\nimport keras.backend as K\nfrom keras.models import load_model\n\n\nfrom keras.preprocessing import text\nfrom keras_preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2022-11-08T06:40:51.046510Z","iopub.execute_input":"2022-11-08T06:40:51.048396Z","iopub.status.idle":"2022-11-08T06:40:58.209664Z","shell.execute_reply.started":"2022-11-08T06:40:51.048317Z","shell.execute_reply":"2022-11-08T06:40:58.208695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Performance Tracking","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nimport wandb\nfrom wandb.keras import WandbCallback\nuser_secrets = UserSecretsClient()\n\n# I have saved my API token with \"wandb_api\" as Label. \n# If you use some other Label make sure to change the same below. \nwandb_api = user_secrets.get_secret(\"wandb_api\")\n\n\nwandb.login(key=wandb_api)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T06:40:58.211729Z","iopub.execute_input":"2022-11-08T06:40:58.212398Z","iopub.status.idle":"2022-11-08T06:40:59.390556Z","shell.execute_reply.started":"2022-11-08T06:40:58.212359Z","shell.execute_reply":"2022-11-08T06:40:59.389559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nfrom wandb.keras import WandbCallback\n\nwandb.init(project=\"CNN-BiLSTM\")","metadata":{"execution":{"iopub.status.busy":"2022-11-08T06:40:59.392021Z","iopub.execute_input":"2022-11-08T06:40:59.392393Z","iopub.status.idle":"2022-11-08T06:41:06.063450Z","shell.execute_reply.started":"2022-11-08T06:40:59.392354Z","shell.execute_reply":"2022-11-08T06:41:06.062544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparmenters ","metadata":{}},{"cell_type":"code","source":"# hyper parameters for this model\n\nmax_len = 150\nembed_size = 300\npre_trained_flag = True\nembed_trainable = False\nemb_weights_init = 'glorot_normal'\noptimizer = 'adam'\nker_regularizer = 'L1L2'\ndecay = True\n\nlr_rate = 0.02\ndrpt = 0.4\nbatch = 258\nnepochs = 50\npatience = 10\ndecay_rate = 0.2\ndecay_after = 5\nfc_act = 'relu'\nfc_weights_init = 'glorot_uniform'","metadata":{"execution":{"iopub.status.busy":"2022-11-08T06:41:06.067897Z","iopub.execute_input":"2022-11-08T06:41:06.077722Z","iopub.status.idle":"2022-11-08T06:41:06.087410Z","shell.execute_reply.started":"2022-11-08T06:41:06.077681Z","shell.execute_reply":"2022-11-08T06:41:06.086542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"258+64","metadata":{"execution":{"iopub.status.busy":"2022-11-08T06:41:06.092787Z","iopub.execute_input":"2022-11-08T06:41:06.095897Z","iopub.status.idle":"2022-11-08T06:41:06.113176Z","shell.execute_reply.started":"2022-11-08T06:41:06.095858Z","shell.execute_reply":"2022-11-08T06:41:06.112068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#embeddingfile = './General_Embeddings/glove.txt'\n#embeddingfile = './General_Embeddings/w2v_cbow.txt'\n#embeddingfile = './General_Embeddings/w2v_sg.txt'\n#embeddingfile = './General_Embeddings/ft_cbow.vec'\nembeddingfile = '../input/final-ruhsp-experiments/General_Embeddings/General_Embeddings/ft_sg.vec'\n\nembedding_matrix = []\nmax_features = 100000\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-08T06:41:06.117723Z","iopub.execute_input":"2022-11-08T06:41:06.120298Z","iopub.status.idle":"2022-11-08T06:41:06.130361Z","shell.execute_reply.started":"2022-11-08T06:41:06.120260Z","shell.execute_reply":"2022-11-08T06:41:06.129330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def hms_string(sec_elapsed):\n    h = int(sec_elapsed / (60 * 60))\n    m = int((sec_elapsed % (60 * 60)) / 60)\n    s = sec_elapsed % 60\n    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T06:41:06.131687Z","iopub.execute_input":"2022-11-08T06:41:06.132739Z","iopub.status.idle":"2022-11-08T06:41:06.147726Z","shell.execute_reply.started":"2022-11-08T06:41:06.132704Z","shell.execute_reply":"2022-11-08T06:41:06.146758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/final-ruhsp-experiments/cleaned_data.csv')\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-08T06:41:06.148813Z","iopub.execute_input":"2022-11-08T06:41:06.149213Z","iopub.status.idle":"2022-11-08T06:41:06.206637Z","shell.execute_reply.started":"2022-11-08T06:41:06.149178Z","shell.execute_reply":"2022-11-08T06:41:06.205751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_coefs( word, *arr ):\n    return word, np.asarray( arr, dtype='float32' )\n\ndef get_vectors( tokenizer ):\n    word_index = tokenizer.word_index\n    num_words = min( max_features, len( word_index ) + 1 )\n    embedding_matrix = np.zeros( ( num_words, embed_size ) )\n    for word, i in word_index.items(  ):\n        if i >= max_features:\n            continue\n        embedding_vector = embeddings_index.get( word )\n        if embedding_vector is not None:\n            embedding_matrix[i] = embedding_vector\n    gc.collect()\n    return embedding_matrix\n\nif pre_trained_flag == True:\n    embeddings_index = dict( get_coefs( *o.rstrip().rsplit(' ') ) for o in open( embeddingfile, encoding='utf-8' ) )","metadata":{"execution":{"iopub.status.busy":"2022-11-08T06:41:06.207820Z","iopub.execute_input":"2022-11-08T06:41:06.208353Z","iopub.status.idle":"2022-11-08T06:41:18.340198Z","shell.execute_reply.started":"2022-11-08T06:41:06.208317Z","shell.execute_reply":"2022-11-08T06:41:18.338998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## stratified K-fold cross-validation\nthe original dataset is randomly partitioned into K folds, where K is a user-specified number. The folds are stratified, meaning that the distribution of the target classes is approximately the same across all folds.","metadata":{}},{"cell_type":"code","source":"skf = StratifiedKFold( n_splits=5, random_state=0, shuffle=True )\nprint(skf)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T06:41:18.343855Z","iopub.execute_input":"2022-11-08T06:41:18.344682Z","iopub.status.idle":"2022-11-08T06:41:18.355113Z","shell.execute_reply.started":"2022-11-08T06:41:18.344643Z","shell.execute_reply":"2022-11-08T06:41:18.354154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Architecture ","metadata":{}},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, Embedding\nfrom keras.layers import CuDNNGRU, CuDNNLSTM, Conv1D, Conv2D, Dense, Bidirectional, GRU, LSTM, MaxPool1D\nfrom keras.layers import SpatialDropout1D, Dropout, Concatenate, concatenate, Softmax, Flatten, Reshape\nfrom keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom keras.optimizers import *\nfrom keras.callbacks import EarlyStopping\n\ndef CNN_BiLSTM( tokenizer, max_len, embed_size=300, embedding_matrix=[], embed_trainable=False,\n            drpt=.1, emb_weights_init='', optimizer='', ker_regularizer='',fc_act='',fc_weights_init=''):\n    inp = Input( shape=(max_len, ), name='InputLayer' )\n    if embedding_matrix == []:\n        x = Embedding( input_dim=len(tokenizer.word_index)+1, output_dim=embed_size,\n                      embeddings_initializer=emb_weights_init, trainable=embed_trainable, name='Embedding' )( inp )\n    else:\n        x = Embedding( input_dim=len(tokenizer.word_index)+1, output_dim=embed_size,\n                      weights=[embedding_matrix], trainable=embed_trainable, name='Embedding' )( inp )\n    x = Dropout( drpt, name='EmbDropout' )( x )\n    conv = Conv1D( filters=64, kernel_size=4, padding='same', activation='relu',\n                  kernel_regularizer=ker_regularizer, name='conv1' )( x )\n    pool1 = MaxPool1D( pool_size=4, name='pool1' )( conv )\n    \n    conv2 = Conv1D( filters=100, kernel_size=4, padding='same', activation='relu',\n                  kernel_regularizer=ker_regularizer, name='conv2' )( x )\n    pool2 = MaxPool1D( pool_size=4, name='pool2' )( conv2 )\n    \n\n    x1 = Bidirectional(CuDNNLSTM( 128, return_sequences=True ), name='BLSTM1' )(pool1)\n    x2 = Bidirectional(CuDNNLSTM( 64, return_sequences=True), name='BLSTM2' )(pool2)\n    \n    conc = concatenate( [ x1, x2 ] )\n\n    pooled = [  ]\n\n    avg_pool = GlobalAveragePooling1D( name='GlobalAvgPool' )(conc)\n    max_pool = GlobalMaxPooling1D( name='GlobalMaxPool' )(conc)\n\n    pooled.append( avg_pool )\n    pooled.append( max_pool )\n\n    x = Concatenate( axis=1, name='ConcatenateLayer' )( pooled )\n\n    x = Dropout( drpt, name='DropoutConcat' ) ( x )\n\n    fc1 = Dense( 100, activation=fc_act, kernel_initializer= fc_weights_init, name='FC1' )( x )\n    x = Dropout( drpt, name='DropoutConcat' ) ( fc1)\n    \n    fc2 = Dense( 50, activation=fc_act, kernel_initializer= fc_weights_init, name='FC2' )( fc1 )\n    outp = Dense( 5, activation='softmax', name='Output' )( fc2 )\n    model = Model( inputs=inp, outputs=outp )\n    \n    \n    model.compile( loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'] )\n#     print(model.summary())\n    return model\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-08T06:41:18.356787Z","iopub.execute_input":"2022-11-08T06:41:18.357402Z","iopub.status.idle":"2022-11-08T06:41:18.378072Z","shell.execute_reply.started":"2022-11-08T06:41:18.357366Z","shell.execute_reply":"2022-11-08T06:41:18.377206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nlr_reduce_callback = tf.keras.callbacks.ReduceLROnPlateau(\n monitor='val_loss', factor=0.1, patience=patience, verbose=1,\n mode='auto', min_delta=1E-7)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-08T06:41:18.380153Z","iopub.execute_input":"2022-11-08T06:41:18.381986Z","iopub.status.idle":"2022-11-08T06:41:18.392621Z","shell.execute_reply.started":"2022-11-08T06:41:18.381948Z","shell.execute_reply":"2022-11-08T06:41:18.391684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warnings.filterwarnings( 'ignore' )\nstart_time = time.time()\n\nvalaccuracy, valprecision, valrecall, valf1, valcm = [], [], [], [], []\ntestaccuracy, testprecision, testrecall, testf1, testcm = [], [], [], [], []\nhistory_ = dict()\nfold = 1\nfor train_index, test_index in skf.split( df.Comment, df.Toxic ):\n    \n    # tokenization with keras tokenizer\n    tokenizer = text.Tokenizer( num_words=max_features )\n    tokenizer.fit_on_texts( df.loc[ train_index ][ 'Comment' ].values.astype('U') )\n\n    traincomments = tokenizer.texts_to_sequences( df.loc[ train_index ][ 'Comment' ].values.astype('U') )\n    testcomments = tokenizer.texts_to_sequences( df.loc[ test_index ][ 'Comment' ].values.astype('U') )\n    \n    # pad the tokenized sequences\n    xtrain =pad_sequences( traincomments, maxlen=max_len )\n    xtest = pad_sequences( testcomments, maxlen=max_len )\n    \n    ytrain = df.loc[ train_index ][ 'Toxic' ].values\n    ytest = df.loc[ test_index ][ 'Toxic' ].values\n    \n    # split train and val\n    xtrain, xval, ytrain, yval = train_test_split( xtrain, ytrain, test_size=0.20, random_state=0 )\n    \n    ytrain = to_categorical( ytrain, 5 )\n    yval = to_categorical( yval, 5 )\n    ytest = to_categorical( ytest, 5 )\n    \n    # check if pre-trained word embeddings flag is true\n    if pre_trained_flag == True:\n        embedding_matrix = get_vectors( tokenizer=tokenizer)\n    \n    # define a model\n    model = CNN_BiLSTM( tokenizer=tokenizer, max_len=max_len, embed_size=embed_size,\n                                   embedding_matrix=embedding_matrix, embed_trainable=embed_trainable,\n                                   emb_weights_init=emb_weights_init, optimizer=optimizer,\n                                   ker_regularizer=ker_regularizer, drpt=drpt,fc_act=fc_act,fc_weights_init=fc_weights_init)\n    \n    K.set_value( model.optimizer.lr, lr_rate )\n    \n    earlystop = EarlyStopping( monitor='val_loss', min_delta=0, patience=patience, verbose=0, mode='auto' )\n\n    history = model.fit( xtrain, ytrain, batch_size=batch, validation_data=( xval,yval ),\n                     epochs=nepochs, verbose=0,callbacks=[WandbCallback(),earlystop] )\n    \n            # save history of each fold\n    history_[ fold ] = history\n   \n    valpredictions = model.predict( xval, verbose=0 )\n    testpredictions =model.predict( xtest, verbose=0)\n    \n    yval = [ np.argmax(y, axis=None, out=None) for y in yval ]\n    ytest = [ np.argmax(y, axis=None, out=None) for y in ytest ]\n\n    valpredictions = [ np.argmax(y, axis=None, out=None) for y in valpredictions ]\n    testpredictions = [ np.argmax(y, axis=None, out=None) for y in testpredictions ] \n    \n    print( 'Fold: {:02d} out of {:02d} completed.'.format( fold, skf.get_n_splits() ) )\n\n    test_report = classification_report( ytest, testpredictions, output_dict=True )\n    testaccuracy.append( test_report[ 'accuracy' ] )\n    testprecision.append( test_report[ 'macro avg' ][ 'precision' ] )\n    testrecall.append( test_report[ 'macro avg' ][ 'recall' ] )\n    testf1.append( test_report[ 'macro avg' ][ 'f1-score' ] )\n    print( classification_report( ytest, testpredictions ) )\n    \n    fold = fold + 1\ntime_took = time.time() - start_time\nprint(f\"Total runtime: {hms_string(time_took)}\")","metadata":{"execution":{"iopub.status.busy":"2022-11-08T06:41:18.396773Z","iopub.execute_input":"2022-11-08T06:41:18.397902Z","iopub.status.idle":"2022-11-08T06:44:51.647229Z","shell.execute_reply.started":"2022-11-08T06:41:18.397866Z","shell.execute_reply":"2022-11-08T06:44:51.646085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finish the run\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2022-11-08T06:44:51.649108Z","iopub.execute_input":"2022-11-08T06:44:51.649882Z","iopub.status.idle":"2022-11-08T06:44:55.314498Z","shell.execute_reply.started":"2022-11-08T06:44:51.649836Z","shell.execute_reply":"2022-11-08T06:44:55.313617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test Set Evaluation over 5-Folds","metadata":{}},{"cell_type":"code","source":"print( 'Test Accuracy' )\nprint( [ '{:0.4f}'.format( x ) for x in testaccuracy ], np.mean( testaccuracy ), '+-', np.std( testaccuracy ), '\\n' )\n\nprint( 'Test Precision' )\nprint( [ '{:0.4f}'.format( x ) for x in testprecision ], np.mean( testprecision ), '+-', np.std( testprecision ), '\\n' )\n\nprint( 'Test Recall' )\nprint( [ '{:0.4f}'.format( x ) for x in testrecall ], np.mean( testrecall ), '+-', np.std( testrecall ), '\\n' )\n\nprint( 'Test F1' )\nprint( [ '{:0.4f}'.format( x ) for x in testf1 ], np.mean( testf1 ), '+-', np.std( testf1 ) )","metadata":{"execution":{"iopub.status.busy":"2022-11-08T06:44:55.316042Z","iopub.execute_input":"2022-11-08T06:44:55.316397Z","iopub.status.idle":"2022-11-08T06:44:55.325106Z","shell.execute_reply.started":"2022-11-08T06:44:55.316360Z","shell.execute_reply":"2022-11-08T06:44:55.323902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training and Evaluation Graphs  Accuracy and Loss","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\ndef plot_graphs(history, metric):\n    plt.plot(history.history[metric])\n    plt.plot(history.history['val_'+metric], '')\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(metric)\n    plt.legend([metric, 'val_'+metric])\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-11-08T06:44:55.326642Z","iopub.execute_input":"2022-11-08T06:44:55.326993Z","iopub.status.idle":"2022-11-08T06:44:55.337433Z","shell.execute_reply.started":"2022-11-08T06:44:55.326957Z","shell.execute_reply":"2022-11-08T06:44:55.336392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(1,figsize=(7,5),dpi=100,clear=True)\nplot_graphs(history_[1], 'accuracy')\nplt.ylim(None, 1)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T06:44:55.340663Z","iopub.execute_input":"2022-11-08T06:44:55.340922Z","iopub.status.idle":"2022-11-08T06:44:55.607303Z","shell.execute_reply.started":"2022-11-08T06:44:55.340897Z","shell.execute_reply":"2022-11-08T06:44:55.606385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(1,figsize=(7,5),dpi=100,clear=True)\nplot_graphs(history_[1], 'loss')\nplt.ylim(0, None)","metadata":{"execution":{"iopub.status.busy":"2022-11-08T06:44:55.608552Z","iopub.execute_input":"2022-11-08T06:44:55.609505Z","iopub.status.idle":"2022-11-08T06:44:55.845678Z","shell.execute_reply.started":"2022-11-08T06:44:55.609453Z","shell.execute_reply":"2022-11-08T06:44:55.844726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Graphs for all Folds","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(30,30),dpi=100,)\n# plt.figure(figsize=(20, 10))\nplt.subplot(5, 2, 1)\nplot_graphs(history_[1], 'accuracy')\nplt.ylim(None, 1)\n\nplt.subplot(5, 2, 2)\nplot_graphs(history_[1], 'loss')\nplt.ylim(0, None)\n\n# 2nd fold \nplt.subplot(5, 2, 3)\nplot_graphs(history_[2], 'accuracy')\nplt.ylim(None, 1)\n\nplt.subplot(5, 2, 4)\nplot_graphs(history_[2], 'loss')\nplt.ylim(0, None)\n\n# 3nd fold \nplt.subplot(5, 2, 5)\nplot_graphs(history_[3], 'accuracy')\nplt.ylim(None, 1)\n\nplt.subplot(5, 2, 6)\nplot_graphs(history_[3], 'loss')\nplt.ylim(0, None)\n\n# 4nd fold \nplt.subplot(5, 2, 7)\nplot_graphs(history_[4], 'accuracy')\nplt.ylim(None, 1)\n\nplt.subplot(5, 2, 8)\nplot_graphs(history_[4], 'loss')\nplt.ylim(0, None)\n\n# 5nd fold \nplt.subplot(5, 2, 9)\nplot_graphs(history_[5], 'accuracy')\nplt.ylim(None, 1)\n\nplt.subplot(5, 2, 10)\nplot_graphs(history_[5], 'loss')\nplt.ylim(0, None)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-08T06:44:55.847141Z","iopub.execute_input":"2022-11-08T06:44:55.848141Z","iopub.status.idle":"2022-11-08T06:44:57.342465Z","shell.execute_reply.started":"2022-11-08T06:44:55.848101Z","shell.execute_reply":"2022-11-08T06:44:57.341614Z"},"trusted":true},"execution_count":null,"outputs":[]}]}